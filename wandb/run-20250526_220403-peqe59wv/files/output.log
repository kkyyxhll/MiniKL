开始载入数据集,path:/home/kkyyxhll/Projects/PythonProjects/MiniKL/data/out/data0.jsonl
数据集载入完成,time:6.091506004333496
device:cuda:0 epoch:[1|1] step:[48|526] lr:[0.0005]:   9%|██████████▏                                                                                                     | 48/526 [01:21<13:32,  1.70s/train, loss=3.6394]
Traceback (most recent call last):
  File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/train/train_pretrain.py", line 127, in <module>
    with torch.amp.autocast(device_type=args.device.split(":")[0], dtype=torch.float16):
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/models/model_minikl.py", line 211, in forward
    x = layer(x, masked=masked)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/models/model_minikl.py", line 185, in forward
    x = x + self.attention(self.norm1(x), masked=masked)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/models/model_minikl.py", line 101, in forward
    attention = F.softmax(attention_score / math.sqrt(self.d_head), dim=-1) @ v
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/train/train_pretrain.py", line 127, in <module>
[rank0]:     with torch.amp.autocast(device_type=args.device.split(":")[0], dtype=torch.float16):
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/models/model_minikl.py", line 211, in forward
[rank0]:     x = layer(x, masked=masked)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/models/model_minikl.py", line 185, in forward
[rank0]:     x = x + self.attention(self.norm1(x), masked=masked)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/anaconda3/envs/dist_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/kkyyxhll/Projects/PythonProjects/MiniKL/models/model_minikl.py", line 101, in forward
[rank0]:     attention = F.softmax(attention_score / math.sqrt(self.d_head), dim=-1) @ v
[rank0]: KeyboardInterrupt
